{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvisraNVbqeR",
        "outputId": "d31bc16a-c098-4ea0-83ba-3e630c519393"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.51.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-1.0.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (0.3.79)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow<22,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-3.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-1.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.11.10)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.4.38)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.10.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting langchain-core\n",
            "  Downloading langchain_core-1.0.3-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.10.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.28.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
            "Downloading streamlit-1.51.0-py3-none-any.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph-1.0.2-py3-none-any.whl (156 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m156.8/156.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl (59.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-3.0.1-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-1.0.2-py3-none-any.whl (34 kB)\n",
            "Downloading langchain_core-1.0.3-py3-none-any.whl (469 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m469.9/469.9 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m104.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m208.3/208.3 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, faiss-cpu, pydeck, langgraph-sdk, langchain-core, bitsandbytes, streamlit, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.79\n",
            "    Uninstalling langchain-core-0.3.79:\n",
            "      Successfully uninstalled langchain-core-0.3.79\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 1.0.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bitsandbytes-0.48.2 faiss-cpu-1.12.0 langchain-core-1.0.3 langgraph-1.0.2 langgraph-checkpoint-3.0.1 langgraph-prebuilt-1.0.2 langgraph-sdk-0.2.9 ormsgpack-1.12.0 pydeck-0.9.1 streamlit-1.51.0\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit sentence-transformers datasets faiss-cpu langgraph langchain-core transformers accelerate bitsandbytes python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dp1vsDYkb0c6",
        "outputId": "389de9a0-3608-46e8-a4f3-b13480475cf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0K\n",
            "added 22 packages in 5s\n",
            "\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0K"
          ]
        }
      ],
      "source": [
        "!npm install -g localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syCj5o5LVkI9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38e4ebcf-4fde-4bd7-c7a0-097f9a8f1270"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import json\n",
        "import faiss\n",
        "import numpy as np\n",
        "import torch\n",
        "from typing import TypedDict, Annotated, Sequence\n",
        "from datasets import Dataset\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "import operator\n",
        "\n",
        "# Page configuration\n",
        "st.set_page_config(\n",
        "    page_title=\"MedLang - Women's Health Assistant\",\n",
        "    page_icon=\"ğŸ¤°\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\"\n",
        ")\n",
        "\n",
        "# Custom CSS for better UI\n",
        "st.markdown(\"\"\"\n",
        "    <style>\n",
        "    .stApp {\n",
        "        background-color: #f5f7fa;\n",
        "    }\n",
        "    .chat-message {\n",
        "        padding: 1.5rem;\n",
        "        border-radius: 0.5rem;\n",
        "        margin-bottom: 1rem;\n",
        "        display: flex;\n",
        "        flex-direction: column;\n",
        "    }\n",
        "    .user-message {\n",
        "        background-color: #e3f2fd;\n",
        "        border-left: 4px solid #2196f3;\n",
        "    }\n",
        "    .assistant-message {\n",
        "        background-color: #f1f8e9;\n",
        "        border-left: 4px solid #8bc34a;\n",
        "    }\n",
        "    .reasoning-box {\n",
        "        background-color: #fff3e0;\n",
        "        border-left: 4px solid #ff9800;\n",
        "        padding: 1rem;\n",
        "        border-radius: 0.5rem;\n",
        "        margin-bottom: 0.5rem;\n",
        "        font-size: 0.9rem;\n",
        "    }\n",
        "    .model-badge {\n",
        "        display: inline-block;\n",
        "        padding: 0.3rem 0.8rem;\n",
        "        border-radius: 1rem;\n",
        "        font-size: 0.85rem;\n",
        "        font-weight: bold;\n",
        "        margin-bottom: 0.5rem;\n",
        "        background-color: #ffebee;\n",
        "        color: #c62828;\n",
        "    }\n",
        "    .stButton>button {\n",
        "        width: 100%;\n",
        "        background-color: #8bc34a;\n",
        "        color: white;\n",
        "    }\n",
        "    .main-header {\n",
        "        text-align: center;\n",
        "        color: #2c3e50;\n",
        "        padding: 2rem 0;\n",
        "    }\n",
        "    .context-box {\n",
        "        background-color: #e1f5fe;\n",
        "        border-left: 4px solid #0277bd;\n",
        "        padding: 0.8rem;\n",
        "        border-radius: 0.5rem;\n",
        "        margin-bottom: 0.5rem;\n",
        "        font-size: 0.85rem;\n",
        "    }\n",
        "    .stats-card {\n",
        "        background-color: white;\n",
        "        padding: 1rem;\n",
        "        border-radius: 0.5rem;\n",
        "        box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n",
        "        margin-bottom: 1rem;\n",
        "    }\n",
        "    </style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "# --- Load environment variables ---\n",
        "@st.cache_resource\n",
        "def load_environment():\n",
        "    load_dotenv()\n",
        "    hf_token = os.getenv(\"HF_TOKEN\")\n",
        "    if not hf_token:\n",
        "        st.error(\"âš ï¸ HF_TOKEN not found in .env file! Please add your HuggingFace access token.\")\n",
        "        st.info(\"Get your token from: https://huggingface.co/settings/tokens\")\n",
        "        st.stop()\n",
        "    return hf_token\n",
        "\n",
        "# --- Initialize embedding model ---\n",
        "@st.cache_resource\n",
        "def initialize_embedder():\n",
        "    return SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "\n",
        "# --- Load Menstrual-LLaMA (Quantized Direct Load) ---\n",
        "@st.cache_resource\n",
        "def load_menstrual_llama(hf_token):\n",
        "    \"\"\"\n",
        "    Load the Menstrual-LLaMA-8B model directly with 4-bit quantization\n",
        "    for efficient use on Colab GPU.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Define 4-bit quantization configuration\n",
        "        bnb_config = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_quant_type=\"nf4\",\n",
        "            bnb_4bit_compute_dtype=torch.bfloat16\n",
        "        )\n",
        "\n",
        "        with st.spinner(\"ğŸ”´ Loading Menstrual-LLaMA-8B model with 4-bit quantization...\"):\n",
        "            model_path = \"proadhikary/Menstrual-LLaMA-8B\"\n",
        "\n",
        "            # 1. Load the tokenizer from the model path\n",
        "            tokenizer = AutoTokenizer.from_pretrained(model_path, token=hf_token)\n",
        "\n",
        "            # 2. Load the model directly, applying 4-bit config\n",
        "            model = AutoModelForCausalLM.from_pretrained(\n",
        "                model_path,\n",
        "                token=hf_token,\n",
        "                quantization_config=bnb_config, # Apply BITSANDBYTES CONFIG\n",
        "                device_map=\"auto\",\n",
        "            )\n",
        "\n",
        "            if tokenizer.pad_token is None:\n",
        "                tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "            model.eval()\n",
        "\n",
        "        # st.success(\"âœ… Menstrual-LLaMA loaded successfully !\") -----> commented this\n",
        "        return model, tokenizer\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"âš ï¸ Could not load Menstrual-LLaMA: {str(e)}\")\n",
        "        st.info(\"This loading method requires your HF_TOKEN to have access to 'proadhikary/Menstrual-LLaMA-8B'. Please check your token and model permissions.\")\n",
        "        st.stop()\n",
        "\n",
        "\n",
        "# --- Load dataset and build FAISS index ---\n",
        "@st.cache_resource\n",
        "def load_dataset_and_index(data_file, _embedder):\n",
        "    try:\n",
        "        qa_pairs = []\n",
        "        with open(data_file, \"r\", encoding=\"utf-8\") as f:\n",
        "            for line in f:\n",
        "                obj = json.loads(line)\n",
        "                qa_pairs.append({\"question\": obj[\"question\"], \"answer\": obj[\"answer\"]})\n",
        "\n",
        "        dataset = Dataset.from_list(qa_pairs)\n",
        "        question_embeddings = _embedder.encode(dataset[\"question\"], convert_to_numpy=True)\n",
        "\n",
        "        dim = question_embeddings.shape[1]\n",
        "        index = faiss.IndexFlatL2(dim)\n",
        "        index.add(question_embeddings)\n",
        "\n",
        "        return dataset, index\n",
        "    except FileNotFoundError:\n",
        "        st.error(f\"âš ï¸ Dataset file '{data_file}' not found! Please ensure it's in the same directory.\")\n",
        "        st.stop()\n",
        "    except Exception as e:\n",
        "        st.error(f\"âš ï¸ Error loading dataset: {str(e)}\")\n",
        "        st.stop()\n",
        "\n",
        "\n",
        "# --- State Definition ---\n",
        "class GraphState(TypedDict):\n",
        "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
        "    question: str\n",
        "    retrieved_context: list\n",
        "    reasoning: str\n",
        "    answer: str\n",
        "\n",
        "\n",
        "# --- Helper Functions ---\n",
        "# Removed language detection function\n",
        "\n",
        "\n",
        "def format_chat_history(messages, max_exchanges=3):\n",
        "    \"\"\"Format recent chat history for context\"\"\"\n",
        "    if not messages:\n",
        "        return \"\"\n",
        "\n",
        "    history_str = \"Previous conversation:\\n\"\n",
        "    for msg in messages[-(max_exchanges*2):]:\n",
        "        if isinstance(msg, HumanMessage):\n",
        "            history_str += f\"User: {msg.content}\\n\"\n",
        "        elif isinstance(msg, AIMessage):\n",
        "            history_str += f\"Assistant: {msg.content}\\n\"\n",
        "    return history_str + \"\\n\"\n",
        "\n",
        "\n",
        "# --- Node Functions ---\n",
        "def retrieve_context(state: GraphState, dataset, index, embedder) -> GraphState:\n",
        "    \"\"\"Retrieve top 2 most relevant Q&A pairs from pregnancy dataset\"\"\"\n",
        "    query = state[\"question\"]\n",
        "\n",
        "    # Search FAISS for top 2 similar questions\n",
        "    query_emb = embedder.encode([query], convert_to_numpy=True)\n",
        "    D, I = index.search(query_emb, 2)\n",
        "\n",
        "    retrieved = [dataset[int(i)] for i in I[0]]\n",
        "\n",
        "    return {\n",
        "        \"retrieved_context\": retrieved\n",
        "    }\n",
        "\n",
        "\n",
        "def generate_reasoning_and_answer(state: GraphState, menstrual_llama, tokenizer) -> GraphState:\n",
        "    \"\"\"\n",
        "    Single unified node: Generate both reasoning and answer using Menstrual-LLaMA\n",
        "    \"\"\"\n",
        "    query = state[\"question\"]\n",
        "    context = state[\"retrieved_context\"]\n",
        "    chat_history = state[\"messages\"][:-1]\n",
        "\n",
        "    # Format retrieved pregnancy context\n",
        "    context_str = \"\"\n",
        "    if context:\n",
        "        context_str = \"\\n\\nRetrieved Pregnancy Knowledge Base (PREGNANCY ONLY - use ONLY if relevant):\\n\"\n",
        "        for i, ctx in enumerate(context):\n",
        "            context_str += f\"\\nReference {i+1}:\\nQ: {ctx['question']}\\nA: {ctx['answer']}\\n\"\n",
        "\n",
        "    # Format chat history for multi-turn conversation\n",
        "    history_str = format_chat_history(chat_history, max_exchanges=3)\n",
        "\n",
        "    # Removed language detection and forceful language instruction\n",
        "\n",
        "    # Construct system message\n",
        "    system_message = \"\"\"You are MedLang, an expert AI assistant for women's health, specializing in BOTH menstrual health and pregnancy. You MUST maintain conversational continuity and use the provided chat history to understand the context of follow-up questions.\n",
        "\n",
        "YOUR KNOWLEDGE:\n",
        "- You have been fine-tuned on 24,000+ expert-verified menstrual health Q&A pairs.\n",
        "- You also have general pregnancy knowledge from your base training.\n",
        "- You are capable of handling questions about periods, menstruation, PMS, PCOS, ovulation, fertility, pregnancy, conception, prenatal care, and more.\n",
        "- You are multilingual and should respond in the same language as the user's query.\n",
        "\"\"\"\n",
        "\n",
        "    # Construct user message with all context\n",
        "    user_message = f\"\"\"\n",
        "{history_str}\n",
        "CURRENT USER QUESTION: {query}\n",
        "\n",
        "{context_str}\n",
        "\n",
        "INSTRUCTIONS FOR ANSWERING:\n",
        "1. REASONING FIRST (2-3 sentences):\n",
        "   - **CRITICAL:** Analyze the **Previous conversation** and the **CURRENT USER QUESTION** together. Identify if this is a follow-up question (e.g., \"What kind?\") and explicitly state what it refers to (e.g., \"What kind of songs for the baby\").\n",
        "   - Identify the primary topic: **Menstrual Health**, **Pregnancy/Fertility**, or **Irrelevant/General**.\n",
        "   - If Menstrual Health, note that you will rely primarily on your internal knowledge.\n",
        "   - If Pregnancy/Fertility, assess if the Retrieved Pregnancy Knowledge Base is relevant.\n",
        "   - **CRITICAL:** If the query is about Menstrual Health (like delayed periods), explicitly state that the RAG context (which is pregnancy-only) is **IGNORED** for the answer.\n",
        "   - Note the query language.\n",
        "\n",
        "2. ANSWER SECOND (4-7 sentences):\n",
        "   - **CRITICAL:** Do NOT give vague answers. Provide **SPECIFIC examples, causes, or types**.\n",
        "   - **For information requiring specific detail (like causes of delayed periods or types of music): use a numbered or bulleted list in the answer.**\n",
        "   - Use your extensive menstrual health knowledge as your PRIMARY source.\n",
        "   - Use the Retrieved Pregnancy Knowledge Base **ONLY** if the query is clearly about a pregnancy topic.\n",
        "   - For severe symptoms or emergencies, always include the standard medical disclaimer.\n",
        "   - CRITICAL: Respond in the SAME language as the user's question.\n",
        "\n",
        "FORMAT YOUR RESPONSE EXACTLY AS:\n",
        "**REASONING:**\n",
        "[Your 2-3 sentence pragmatic inference here]\n",
        "\n",
        "**ANSWER:**\n",
        "[Your detailed, specific, and structured response here, including lists where appropriate]\"\"\"\n",
        "\n",
        "    try:\n",
        "        # Use the chat template as specified in HuggingFace model card\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": system_message},\n",
        "            {\"role\": \"user\", \"content\": user_message},\n",
        "        ]\n",
        "\n",
        "        # Apply chat template (LLaMA-3 format)\n",
        "        input_ids = tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            add_generation_prompt=True,\n",
        "            return_tensors=\"pt\"\n",
        "        ).to(menstrual_llama.device)\n",
        "\n",
        "        # Terminators as specified in model card\n",
        "        terminators = [\n",
        "            tokenizer.eos_token_id,\n",
        "            tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "        ]\n",
        "\n",
        "        # Disable specific CUDA optimizations as per model card\n",
        "        if torch.cuda.is_available():\n",
        "            torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
        "            torch.backends.cuda.enable_flash_sdp(False)\n",
        "\n",
        "        # Generate with parameters from model card\n",
        "        with torch.no_grad():\n",
        "            outputs = menstrual_llama.generate(\n",
        "                input_ids,\n",
        "                pad_token_id=tokenizer.pad_token_id,\n",
        "                max_new_tokens=400,\n",
        "                eos_token_id=terminators,\n",
        "                do_sample=True,\n",
        "                temperature=0.6,  # As per model card\n",
        "                top_p=0.9\n",
        "            )\n",
        "\n",
        "        # Extract only the generated response\n",
        "        response = outputs[0][input_ids.shape[-1]:]\n",
        "        response_text = tokenizer.decode(response, skip_special_tokens=True)\n",
        "\n",
        "        # Parse reasoning and answer\n",
        "        reasoning = \"\"\n",
        "        answer = \"\"\n",
        "\n",
        "        if \"**REASONING:**\" in response_text and \"**ANSWER:**\" in response_text:\n",
        "            parts = response_text.split(\"**ANSWER:**\")\n",
        "            reasoning = parts[0].replace(\"**REASONING:**\", \"\").strip()\n",
        "            answer = parts[1].strip()\n",
        "        elif \"REASONING:\" in response_text and \"ANSWER:\" in response_text:\n",
        "            parts = response_text.split(\"ANSWER:\")\n",
        "            reasoning = parts[0].replace(\"REASONING:\", \"\").strip()\n",
        "            answer = parts[1].strip()\n",
        "        else:\n",
        "            # Fallback: treat entire response as answer\n",
        "            answer = response_text\n",
        "            reasoning = \"Analyzing query and generating response based on training knowledge.\"\n",
        "\n",
        "        return {\n",
        "            \"reasoning\": reasoning,\n",
        "            \"answer\": answer,\n",
        "            \"messages\": [AIMessage(content=answer)]\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"I apologize, but I encountered an error processing your question. Error: {str(e)}\"\n",
        "        return {\n",
        "            \"reasoning\": \"Error occurred during processing\",\n",
        "            \"answer\": error_msg,\n",
        "            \"messages\": [AIMessage(content=error_msg)]\n",
        "        }\n",
        "\n",
        "\n",
        "# --- Build the Graph ---\n",
        "@st.cache_resource\n",
        "def create_chatbot_graph(_embedder, _dataset, _index, _menstrual_llama, _tokenizer):\n",
        "    \"\"\"Create the LangGraph workflow with Menstrual-LLaMA\"\"\"\n",
        "    workflow = StateGraph(GraphState)\n",
        "\n",
        "    # Add nodes\n",
        "    workflow.add_node(\n",
        "        \"retrieve\",\n",
        "        lambda state: retrieve_context(state, _dataset, _index, _embedder)\n",
        "    )\n",
        "\n",
        "    workflow.add_node(\n",
        "        \"reason_and_answer\",\n",
        "        lambda state: generate_reasoning_and_answer(state, _menstrual_llama, _tokenizer)\n",
        "    )\n",
        "\n",
        "    # Add edges: retrieve â†’ reason_and_answer â†’ END\n",
        "    workflow.add_edge(\"retrieve\", \"reason_and_answer\")\n",
        "    workflow.add_edge(\"reason_and_answer\", END)\n",
        "\n",
        "    # Set entry point\n",
        "    workflow.set_entry_point(\"retrieve\")\n",
        "\n",
        "    # Compile with memory for multi-turn conversations\n",
        "    memory = MemorySaver()\n",
        "    app = workflow.compile(checkpointer=memory)\n",
        "\n",
        "    return app\n",
        "\n",
        "\n",
        "# --- Initialize Session State ---\n",
        "def initialize_session_state():\n",
        "    if \"messages\" not in st.session_state:\n",
        "        st.session_state.messages = []\n",
        "    if \"thread_id\" not in st.session_state:\n",
        "        import uuid\n",
        "        st.session_state.thread_id = str(uuid.uuid4())\n",
        "    if \"show_reasoning\" not in st.session_state:\n",
        "        st.session_state.show_reasoning = True\n",
        "    if \"show_context\" not in st.session_state:\n",
        "        st.session_state.show_context = False\n",
        "    if \"query_count\" not in st.session_state:\n",
        "        st.session_state.query_count = 0\n",
        "\n",
        "\n",
        "# --- Main App ---\n",
        "def main():\n",
        "    # Initialize\n",
        "    initialize_session_state()\n",
        "    hf_token = load_environment()\n",
        "    embedder = initialize_embedder()\n",
        "\n",
        "    # Load Menstrual-LLaMA with access token\n",
        "    menstrual_llama, tokenizer = load_menstrual_llama(hf_token)\n",
        "\n",
        "    # Sidebar\n",
        "    with st.sidebar:\n",
        "        st.markdown(\"### ğŸ¤° MedLang\")\n",
        "        st.markdown(\"*Women's Health Companion*\")\n",
        "        st.markdown(\"---\")\n",
        "\n",
        "        # Dataset file input\n",
        "        data_file = st.text_input(\n",
        "            \"Pregnancy Dataset Path\",\n",
        "            value=\"merged_preg_dataset.jsonl\",\n",
        "            help=\"Path to your pregnancy Q&A JSONL file (1,378 pairs)\"\n",
        "        )\n",
        "\n",
        "        # Load dataset and create graph\n",
        "        if st.button(\"ğŸ”„ Reload Dataset & Model\"):\n",
        "            st.cache_resource.clear()\n",
        "            st.rerun()\n",
        "\n",
        "        dataset, index = load_dataset_and_index(data_file, embedder)\n",
        "        app = create_chatbot_graph(embedder, dataset, index, menstrual_llama, tokenizer)\n",
        "\n",
        "        # st.success(f\"âœ… {len(dataset)} pregnancy Q&A pairs loaded\")\n",
        "        # st.success(\"âœ… Menstrual-LLaMA-8B active (Quantized Load)\")\n",
        "        # st.info(\"â„¹ï¸ Model trained on 24k+ menstrual Q&As\")\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "\n",
        "        # Settings\n",
        "        st.markdown(\"### âš™ï¸ Display Settings\")\n",
        "        st.session_state.show_reasoning = st.checkbox(\n",
        "            \"Show Reasoning Process\",\n",
        "            value=st.session_state.show_reasoning,\n",
        "            help=\"Display the model's internal reasoning\"\n",
        "        )\n",
        "        st.session_state.show_context = st.checkbox(\n",
        "            \"Show Retrieved Context\",\n",
        "            value=st.session_state.show_context,\n",
        "            help=\"Display pregnancy Q&As retrieved from RAG\"\n",
        "        )\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "\n",
        "        # # Statistics\n",
        "        # st.markdown(\"### ğŸ“Š Session Statistics\")\n",
        "        # st.markdown(f\"\"\"\n",
        "        # <div class=\"stats-card\">\n",
        "        #     <strong>Total Queries:</strong> {st.session_state.query_count}<br>\n",
        "        # </div>\n",
        "        # \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        # st.markdown(\"---\")\n",
        "\n",
        "        # Clear conversation\n",
        "        if st.button(\"ğŸ—‘ï¸ Clear Conversation\"):\n",
        "            st.session_state.messages = []\n",
        "            st.session_state.query_count = 0\n",
        "            # Removed language_stats reset\n",
        "            import uuid\n",
        "            st.session_state.thread_id = str(uuid.uuid4())\n",
        "            st.rerun()\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "        st.markdown(\"### â„¹ï¸ About MedLang\")\n",
        "        st.markdown(\"\"\"\n",
        "        **Model Architecture:**\n",
        "        - ğŸ”´ **Menstrual-LLaMA**: Fine-tuned on 24,000+ expert-verified menstrual health Q&A pairs\n",
        "        - ğŸ“š **RAG Enhancement**: Retrieves relevant pregnancy Q&As when needed\n",
        "        - ğŸ§  **Autonomous Decision Making**: Model intelligently decides when to use retrieved context\n",
        "\n",
        "        **Capabilities:**\n",
        "        - âœ… Menstrual health (periods, PMS, PCOS, ovulation)\n",
        "        - âœ… Pregnancy (conception, prenatal care, symptoms)\n",
        "        - âœ… Fertility & reproductive health\n",
        "        - âœ… Multi-turn conversations with memory\n",
        "        - âœ… Multilingual queries supported\n",
        "\n",
        "        **Features:**\n",
        "        - Context-aware responses\n",
        "        - Conversational memory via LangGraph\n",
        "        - Reasoning transparency\n",
        "        - Privacy-focused\n",
        "        \"\"\")\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "        st.markdown(\"### ğŸ’¡ Example Questions\")\n",
        "        st.markdown(\"\"\"\n",
        "        - \"What causes irregular periods?\"\n",
        "        - \"Is cramping normal in early pregnancy?\"\n",
        "        - \"How can I track my ovulation?\"\n",
        "        - \"à¤®à¤¾à¤¸à¤¿à¤• à¤§à¤°à¥à¤® à¤®à¥‡à¤‚ à¤¦à¥‡à¤°à¥€ à¤•à¥‡ à¤•à¥à¤¯à¤¾ à¤•à¤¾à¤°à¤£ à¤¹à¥ˆà¤‚?\"\n",
        "        - \"à¤—à¤°à¥à¤­à¤¾à¤µà¤¸à¥à¤¥à¤¾ à¤•à¥‡ à¤¶à¥à¤°à¥à¤†à¤¤à¥€ à¤²à¤•à¥à¤·à¤£ à¤•à¥à¤¯à¤¾ à¤¹à¥ˆà¤‚?\"\n",
        "        \"\"\")\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "        st.markdown(\"âš ï¸ *This is not a substitute for professional medical advice. Always consult a healthcare provider for serious concerns.*\")\n",
        "\n",
        "    # Main chat interface\n",
        "    st.markdown(\"<h1 class='main-header'>ğŸ¤° MedLang - Women's Health Companion</h1>\",\n",
        "                unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"\"\"\n",
        "    <div style='text-align: center; color: #666; margin-bottom: 2rem;'>\n",
        "    Ask questions about <b>pregnancy</b> or <b>menstrual health</b> ğŸŒ<br>\n",
        "    <em>Powered by Menstrual-LLaMA-8B with RAG enhancement</em>\n",
        "    </div>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    # Display chat messages\n",
        "    for message in st.session_state.messages:\n",
        "        if message[\"role\"] == \"user\":\n",
        "            with st.container():\n",
        "                st.markdown(f\"\"\"\n",
        "                    <div class=\"chat-message user-message\">\n",
        "                        <strong>ğŸ‘¤ You:</strong><br>\n",
        "                        {message[\"content\"]}\n",
        "                    </div>\n",
        "                \"\"\", unsafe_allow_html=True)\n",
        "        else:\n",
        "            with st.container():\n",
        "                # Model badge\n",
        "                st.markdown(\"\"\"\n",
        "                    <span class=\"model-badge\">\n",
        "                        ğŸ”´ Menstrual-LLaMA-8B\n",
        "                    </span>\n",
        "                \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "                # Retrieved context (if enabled)\n",
        "                if st.session_state.show_context and \"context\" in message and message[\"context\"]:\n",
        "                    st.markdown(\"<strong>ğŸ“š Retrieved Pregnancy Context (RAG):</strong>\", unsafe_allow_html=True)\n",
        "                    for i, ctx in enumerate(message[\"context\"]):\n",
        "                        with st.expander(f\"Reference {i+1}: {ctx['question'][:80]}...\", expanded=False):\n",
        "                            st.markdown(f\"**Q:** {ctx['question']}\")\n",
        "                            st.markdown(f\"**A:** {ctx['answer'][:300]}...\")\n",
        "\n",
        "                # Reasoning (if enabled)\n",
        "                if st.session_state.show_reasoning and \"reasoning\" in message and message[\"reasoning\"]:\n",
        "                    st.markdown(f\"\"\"\n",
        "                        <div class=\"reasoning-box\">\n",
        "                            <strong>ğŸ§  Model Reasoning:</strong><br>\n",
        "                            {message[\"reasoning\"]}\n",
        "                        </div>\n",
        "                    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "                # Answer\n",
        "                st.markdown(f\"\"\"\n",
        "                    <div class=\"chat-message assistant-message\">\n",
        "                        <strong>ğŸ¤– MedLang:</strong><br>\n",
        "                        {message[\"content\"]}\n",
        "                    </div>\n",
        "                \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    # Chat input\n",
        "    user_input = st.chat_input(\"Ask about pregnancy or menstrual health...\")\n",
        "\n",
        "    if user_input:\n",
        "        # Update query count\n",
        "        st.session_state.query_count += 1\n",
        "\n",
        "        # Add user message\n",
        "        st.session_state.messages.append({\n",
        "            \"role\": \"user\",\n",
        "            \"content\": user_input\n",
        "        })\n",
        "\n",
        "        # Display user message immediately\n",
        "        with st.container():\n",
        "            st.markdown(f\"\"\"\n",
        "                <div class=\"chat-message user-message\">\n",
        "                    <strong>ğŸ‘¤ You:</strong><br>\n",
        "                    {user_input}\n",
        "                </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        # Generate response\n",
        "        with st.spinner(\"ğŸ¤” Thinking...\"):\n",
        "            try:\n",
        "                # Prepare initial state with conversation history\n",
        "                history_messages = [msg for msg in st.session_state.messages[:-1]\n",
        "                                   if isinstance(msg.get(\"content\"), str)]\n",
        "\n",
        "                langchain_history = []\n",
        "                for msg in history_messages:\n",
        "                    if msg[\"role\"] == \"user\":\n",
        "                        langchain_history.append(HumanMessage(content=msg[\"content\"]))\n",
        "                    else:\n",
        "                        langchain_history.append(AIMessage(content=msg[\"content\"]))\n",
        "\n",
        "                initial_state = {\n",
        "                    \"messages\": langchain_history + [HumanMessage(content=user_input)],\n",
        "                    \"question\": user_input,\n",
        "                    \"retrieved_context\": [],\n",
        "                    \"reasoning\": \"\",\n",
        "                    \"answer\": \"\"\n",
        "                }\n",
        "\n",
        "                config = {\"configurable\": {\"thread_id\": st.session_state.thread_id}}\n",
        "                result = app.invoke(initial_state, config)\n",
        "\n",
        "                # Add assistant message\n",
        "                st.session_state.messages.append({\n",
        "                    \"role\": \"assistant\",\n",
        "                    \"content\": result[\"answer\"],\n",
        "                    \"reasoning\": result[\"reasoning\"],\n",
        "                    \"context\": result[\"retrieved_context\"]\n",
        "                })\n",
        "\n",
        "                st.rerun()\n",
        "\n",
        "            except Exception as e:\n",
        "                st.error(f\"âš ï¸ Error: {str(e)}\")\n",
        "                st.error(\"Please try rephrasing your question or check the model setup.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac7eSdQEb_C6",
        "outputId": "62e6a1d8-714c-486e-a985-64f7eb012f51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.227.165.190\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kyour url is: https://warm-bugs-walk.loca.lt\n"
          ]
        }
      ],
      "source": [
        "# # Run the Streamlit app in the background\n",
        "# !nohup streamlit run medlang-app.py &\n",
        "\n",
        "# # Wait a moment for Streamlit to initialize\n",
        "# import time\n",
        "# time.sleep(5)\n",
        "\n",
        "# # Use localtunnel to expose port 8501\n",
        "# print(\"Streamlit App is running. Click the link below:\")\n",
        "# !lt --port 8501 --subdomain medlang-app & curl https://loca.lt/mytunnelpassword\n",
        "\n",
        "!streamlit run app.py &>/content/logs.txt & npx localtunnel --port 8501 & curl https://loca.lt/mytunnelpassword"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hofhLxczwGrb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "05e30cbdf47a42518df13f6bf58e85b4",
            "59383bcce8e04515b9fa074e7fee7df8",
            "7e7f696ce5544e30911f07c46dbbc061",
            "0fb328555ac848efbb4ff9f30057142b",
            "66f90f324d414810a9e86421aa507dcf",
            "98b06d9b301040f78bd37d6fedc2efeb",
            "46ff99c632f848fd9795201cfe2d4591",
            "14e648809751439fa9b5ae61b87ce684",
            "1ed4dd71da86494ea10f4443a5f1b1da",
            "774c8c26392441daa8b0090f7861a816",
            "d8914704a2674776b783a8c0eb86cdfb"
          ]
        },
        "outputId": "7bfe5094-5cd1-4fca-8b8e-eff5edefd626"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 1. Loading Models and Data ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
            "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
            "You are not authenticated with the Hugging Face Hub in this notebook.\n",
            "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading Menstrual-LLaMA-8B with 4-bit quantization...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05e30cbdf47a42518df13f6bf58e85b4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded successfully.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RAG Index loaded with 942 documents.\n",
            "Golden Test Set loaded with 120 queries.\n",
            "\n",
            "--- 2. Running Evaluation ---\n",
            "Query 1/120: What is the scientific term for \"chumps\" or \"perio...\n",
            "Query 2/120: What is â€œmenarcheâ€?...\n",
            "Query 3/120: At what age do menses usually begin?...\n",
            "Query 4/120: What happens during menses?...\n",
            "Query 5/120: For how long does the bleeding last?...\n",
            "Query 6/120: Is it very painful?...\n",
            "Query 7/120: What is a sanitary pad?...\n",
            "Query 8/120: Is it okay to use a cloth instead of a sanitary pa...\n",
            "Query 9/120: Are sanitary pads too costly?...\n",
            "Query 10/120: Can sanitary pads be availed free of cost?...\n",
            "Query 11/120: What needs to be done after using a sanitary pad?...\n",
            "Query 12/120: What is the proper way to dispose of sanitary pads...\n",
            "Query 13/120: Can sanitary pads be disposed of in a commode?...\n",
            "Query 14/120: How many sanitary pads are required per month?...\n",
            "Query 15/120: How often should sanitary pads be changed during t...\n",
            "Query 16/120: What will happen if I use the same sanitary pad fo...\n",
            "Query 17/120: Is there an alternative to sanitary pads?...\n",
            "Query 18/120: Can a virgin use a menstrual cup?...\n",
            "Query 19/120: Are menstrual cups reusable?...\n",
            "Query 20/120: What is a tampon?...\n",
            "Query 21/120: Are tampons reusable?...\n",
            "Query 22/120: What is the proper way to dispose of tampons?...\n",
            "Query 23/120: How do I take the tampon out of my vagina?...\n",
            "Query 24/120: What will happen if the tampon does not come out?...\n",
            "Query 25/120: Do I need training before using a tampon?...\n",
            "Query 26/120: What should I do if a tampon is stuck inside and i...\n",
            "Query 27/120: Why do infections occur if sanitary pads or tampon...\n",
            "Query 28/120: What type of food should I eat during menses?...\n",
            "Query 29/120: What are some rules of hygiene during menses?...\n",
            "Query 30/120: Why do elders insist on not having a head bath dur...\n",
            "Query 31/120: What is premenstrual syndrome that people usually ...\n",
            "Query 32/120: Why does one get premenstrual syndrome?...\n",
            "Query 33/120: What kind of exercise should I do during menses?...\n",
            "Query 34/120: Can I prepone or postpone my period?...\n",
            "Query 35/120: What kind of clothes should be worn during menses?...\n",
            "Query 36/120: How can I keep track of my menstrual cycle?...\n",
            "Query 37/120: Is it normal for my period to smell?...\n",
            "Query 38/120: What are the common reasons for missed or late per...\n",
            "Query 39/120: How much blood do I lose during my period?...\n",
            "Query 40/120: When will I stop having my period for good?...\n",
            "Query 41/120: Am I pregnant if I miss my periods?...\n",
            "Query 42/120: Why did I bleed for more days in this cycle?...\n",
            "Query 43/120: Are my painful cramps normal? When should I tell m...\n",
            "Query 44/120: Is it normal to have periods twice a month?...\n",
            "Query 45/120: Where is the uterus located?...\n",
            "Query 46/120: Which organs are responsible for menstruation?...\n",
            "Query 47/120: How many ovaries are present in a woman?...\n",
            "Query 48/120: What is the normal interval between two menstrual ...\n",
            "Query 49/120: How many eggs are normally released in a month?...\n",
            "Query 50/120: What is a sign of ovulation?...\n",
            "Query 51/120: What foods should I avoid or limit while breastfee...\n",
            "Query 52/120: How can I manage extreme tiredness or exhaustion d...\n",
            "Query 53/120: What steps should I take to treat a clogged milk d...\n",
            "Query 54/120: How many necessary vaccines are recommended for my...\n",
            "Query 55/120: At what temperature should I be concerned about my...\n",
            "Query 56/120: Why is my baby consistently congested every single...\n",
            "Query 57/120: Around what age do most babies begin talking or sp...\n",
            "Query 58/120: How frequently is it appropriate or necessary to s...\n",
            "Query 59/120: What is the typical visual acuity for a 4-month-ol...\n",
            "Query 60/120: Is my baby able to detect light when I am 18 weeks...\n",
            "Query 61/120: What range is considered a normal blood pressure r...\n",
            "Query 62/120: What sensory experiences are infants typically hav...\n",
            "Query 63/120: When is the recommended time or age for me to stop...\n",
            "Query 64/120: What is the best time to switch my baby from formu...\n",
            "Query 65/120: How frequently should I be feeding my baby?...\n",
            "Query 66/120: What are some engaging and age-appropriate games I...\n",
            "Query 67/120: Is it better for my baby to use a pacifier or suck...\n",
            "Query 68/120: What is the most effective method to encourage my ...\n",
            "Query 69/120: My two-year-old is not communicating. What might b...\n",
            "Query 70/120: How can I determine if my baby is having an allerg...\n",
            "Query 71/120: What is the normal and reassuring frequency for fe...\n",
            "Query 72/120: Is experiencing heartburn a common symptom at 21 w...\n",
            "Query 73/120: Can I hear or feel my baby's joints crack or pop?...\n",
            "Query 74/120: What amount of crying is considered normal for a n...\n",
            "Query 75/120: What is the underlying cause for my constant feeli...\n",
            "Query 76/120: I am experiencing fatigue and weakness; what are t...\n",
            "Query 77/120: Why am I constantly feeling exhausted and physical...\n",
            "Query 78/120: Could you list the reasons for feeling fatigued an...\n",
            "Query 79/120: Why do I experience pain or a burning sensation wh...\n",
            "Query 80/120: What causes the pain or burning sensation during u...\n",
            "Query 81/120: What's the reason for the painful or burning feeli...\n",
            "Query 82/120: What could be causing the burning sensation when I...\n",
            "Query 83/120: I have fever, tiredness, and shakiness. What shoul...\n",
            "Query 84/120: What are the possible causes for my fever, fatigue...\n",
            "Query 85/120: Why am I feeling feverish, fatigued, and shaky?...\n",
            "Query 86/120: Could you tell me the reasons for feeling feverish...\n",
            "Query 87/120: What is the cause of my sad or depressed mood?...\n",
            "Query 88/120: What are the possible causes for my persistent low...\n",
            "Query 89/120: Why do I feel depressed or generally down?...\n",
            "Query 90/120: What are the reasons for feeling sad or consistent...\n",
            "Query 91/120: What are the causes of my high blood pressure duri...\n",
            "Query 92/120: Could you list the factors causing my elevated blo...\n",
            "Query 93/120: What are the potential reasons for hypertension du...\n",
            "Query 94/120: What leads to elevated blood pressure during the p...\n",
            "Query 95/120: What is the reason my blood glucose levels are hig...\n",
            "Query 96/120: What are the risk factors for having high blood su...\n",
            "Query 97/120: What leads to elevated glucose levels during pregn...\n",
            "Query 98/120: Can you explain the causes of high blood sugar in ...\n",
            "Query 99/120: Could you define what preeclampsia is and list its...\n",
            "Query 100/120: I need an explanation of preeclampsia during pregn...\n",
            "Query 101/120: Can you give me the details regarding the conditio...\n",
            "Query 102/120: How should I understand the term preeclampsia in t...\n",
            "Query 103/120: Why am I experiencing labor pains before my expect...\n",
            "Query 104/120: What causes the contractions I am feeling before m...\n",
            "Query 105/120: Why are my labor pains starting so early?...\n",
            "Query 106/120: Could you explain the reasons for having contracti...\n",
            "Query 107/120: Why am I vomiting so frequently during my pregnanc...\n",
            "Query 108/120: What could be the cause of my excessive vomiting t...\n",
            "Query 109/120: What is the reason I am experiencing frequent, sev...\n",
            "Query 110/120: What causes severe vomiting during pregnancy, like...\n",
            "Query 111/120: What is the cause of my swollen feet during pregna...\n",
            "Query 112/120: I have swelling in my feet. What might be causing ...\n",
            "Query 113/120: Why have my feet become swollen during my pregnanc...\n",
            "Query 114/120: Are swollen feet a normal symptom of pregnancy? Wh...\n",
            "Query 115/120: Can you list the risks associated with obesity dur...\n",
            "Query 116/120: How does pre-pregnancy obesity impact potential co...\n",
            "Query 117/120: What are the consequences of being obese before an...\n",
            "Query 118/120: Is it possible for a malaria infection to cause a ...\n",
            "Query 119/120: What dangers does malaria pose to pregnant women a...\n",
            "Query 120/120: How specifically does malaria impact the course of...\n",
            "\n",
            "==================================================\n",
            "         MEDLANG EVALUATION SUMMARY\n",
            "==================================================\n",
            "Total Queries Tested: 120\n",
            "Total Runtime: 1727.23 seconds\n",
            "Average Inference Time: 14.39 seconds/query\n",
            "\n",
            "--- METRICS ---\n",
            "1. Semantic Similarity Score (Avg.): 0.7733 (Goal: > 0.85)\n",
            "2. Retrieval Accuracy@2 (RAG Queries): 0.8571 (60/70 correct)\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "import operator\n",
        "import time\n",
        "from typing import TypedDict, Annotated, Sequence\n",
        "from datasets import Dataset\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "TEST_SET_FILE = \"test_set.jsonl\" # This is the file you create\n",
        "DATASET_FILE = \"merged_preg_dataset.jsonl\" # Your original RAG data\n",
        "MODEL_PATH = \"proadhikary/Menstrual-LLaMA-8B\"\n",
        "\n",
        "# --- Helper Functions from app.py (Modified slightly for standalone script) ---\n",
        "\n",
        "# Note: Simplified version of load_menstrual_llama without Streamlit caching/spinner\n",
        "def load_menstrual_llama_eval():\n",
        "    load_dotenv()\n",
        "    hf_token = os.getenv(\"HF_TOKEN\")\n",
        "    if not hf_token:\n",
        "        print(\"ERROR: HF_TOKEN not found in .env file.\")\n",
        "        return None, None\n",
        "\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16\n",
        "    )\n",
        "\n",
        "    print(\"Loading Menstrual-LLaMA-8B with 4-bit quantization...\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, token=hf_token)\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        MODEL_PATH,\n",
        "        token=hf_token,\n",
        "        quantization_config=bnb_config,\n",
        "        device_map=\"auto\",\n",
        "    )\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "    model.eval()\n",
        "    print(\"Model loaded successfully.\")\n",
        "    return model, tokenizer\n",
        "\n",
        "# Helper function to compute semantic similarity\n",
        "def calculate_semantic_similarity(generated_answer, ground_truth, embedder):\n",
        "    \"\"\"Calculates cosine similarity between the embeddings of the two texts.\"\"\"\n",
        "    if not generated_answer or not ground_truth:\n",
        "        return 0.0\n",
        "\n",
        "    embeddings = embedder.encode(\n",
        "        [generated_answer, ground_truth],\n",
        "        convert_to_numpy=True\n",
        "    )\n",
        "    # Cosine similarity between the two vectors\n",
        "    return cosine_similarity(\n",
        "        embeddings[0].reshape(1, -1),\n",
        "        embeddings[1].reshape(1, -1)\n",
        "    )[0][0]\n",
        "\n",
        "# --- LangGraph Nodes (simplified, using logic from app.py) ---\n",
        "\n",
        "class GraphState(TypedDict):\n",
        "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
        "    question: str\n",
        "    retrieved_context: list\n",
        "    reasoning: str\n",
        "    answer: str\n",
        "\n",
        "def retrieve_context(state, dataset, index, embedder):\n",
        "    query = state[\"question\"]\n",
        "    query_emb = embedder.encode([query], convert_to_numpy=True)\n",
        "    D, I = index.search(query_emb, 2)\n",
        "    retrieved = [dataset[int(i)] for i in I[0]]\n",
        "    return {\"retrieved_context\": retrieved}\n",
        "\n",
        "def generate_reasoning_and_answer(state, menstrual_llama, tokenizer):\n",
        "    \"\"\"\n",
        "    Evaluation version of the generation node with simplified single-turn prompt\n",
        "    that forces specificity and RAG decision making.\n",
        "    \"\"\"\n",
        "    query = state[\"question\"]\n",
        "    context = state[\"retrieved_context\"]\n",
        "\n",
        "    # 1. Format retrieved pregnancy context\n",
        "    context_str = \"\"\n",
        "    if context:\n",
        "        context_str = \"\\n\\nRetrieved Pregnancy Knowledge Base (PREGNANCY ONLY - use ONLY if relevant):\\n\"\n",
        "        for i, ctx in enumerate(context):\n",
        "            context_str += f\"\\nReference {i+1}:\\nQ: {ctx['question']}\\nA: {ctx['answer']}\\n\"\n",
        "\n",
        "    # 2. Construct System Message (Simplified persona)\n",
        "    system_message = \"\"\"You are MedLang, an expert AI assistant for women's health, specializing in BOTH menstrual health and pregnancy. Your goal is to provide concise, structured, and factual medical information.\n",
        "\n",
        "YOUR KNOWLEDGE:\n",
        "- You have been fine-tuned on 24,000+ expert-verified menstrual health Q&A pairs.\n",
        "- You have general pregnancy knowledge.\n",
        "- You are capable of handling questions about periods, PCOS, pregnancy, and more.\n",
        "\"\"\"\n",
        "\n",
        "    # 3. Construct User Message (Focus on RAG/Specificity Instructions)\n",
        "    user_message = f\"\"\"CURRENT USER QUESTION: {query}\n",
        "\n",
        "{context_str}\n",
        "\n",
        "INSTRUCTIONS FOR ANSWERING:\n",
        "1. REASONING FIRST (2-3 sentences):\n",
        "   - Identify the primary topic: **Menstrual Health** or **Pregnancy/Fertility**.\n",
        "   - If Menstrual Health, explicitly state that the RAG context (which is pregnancy-only) is **IGNORED** for the answer.\n",
        "   - If Pregnancy/Fertility, assess if the Retrieved Pregnancy Knowledge Base is relevant and state whether it will be used.\n",
        "\n",
        "2. ANSWER SECOND (4-7 sentences):\n",
        "   - **CRITICAL:** Do NOT give vague answers like \"various reasons\" or \"various songs.\" Provide **SPECIFIC examples, causes, or types**.\n",
        "   - **For information requiring specific detail, use a numbered or bulleted list in the answer.**\n",
        "   - Use your extensive menstrual health knowledge as your PRIMARY source.\n",
        "   - Use the Retrieved Pregnancy Knowledge Base **ONLY** if the query is clearly about a pregnancy topic.\n",
        "   - For severe symptoms or emergencies, always include the standard medical disclaimer: \"Please consult a healthcare provider immediately for personalized medical advice.\"\n",
        "\n",
        "FORMAT YOUR RESPONSE EXACTLY AS:\n",
        "**REASONING:**\n",
        "[Your 2-3 sentence pragmatic inference here]\n",
        "\n",
        "**ANSWER:**\n",
        "[Your detailed, specific, and structured response here, including lists where appropriate]\"\"\"\n",
        "\n",
        "    # 4. Invoke the model\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": user_message},\n",
        "    ]\n",
        "\n",
        "    input_ids = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        add_generation_prompt=True,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(menstrual_llama.device)\n",
        "\n",
        "    terminators = [tokenizer.eos_token_id, tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = menstrual_llama.generate(\n",
        "            input_ids,\n",
        "            pad_token_id=tokenizer.pad_token_id,\n",
        "            max_new_tokens=400,\n",
        "            eos_token_id=terminators,\n",
        "            do_sample=False, # Use deterministic generation for better eval consistency\n",
        "            temperature=0.6,\n",
        "            top_p=0.9\n",
        "        )\n",
        "\n",
        "    response = outputs[0][input_ids.shape[-1]:]\n",
        "    response_text = tokenizer.decode(response, skip_special_tokens=True).strip()\n",
        "\n",
        "    # Parse reasoning and answer from structured output\n",
        "    reasoning = \"N/A (Parsing Error)\"\n",
        "    answer = response_text\n",
        "\n",
        "    if \"**REASONING:**\" in response_text and \"**ANSWER:**\" in response_text:\n",
        "        parts = response_text.split(\"**ANSWER:**\")\n",
        "        reasoning = parts[0].replace(\"**REASONING:**\", \"\").strip()\n",
        "        answer = parts[1].strip()\n",
        "\n",
        "    return {\n",
        "        \"reasoning\": reasoning,\n",
        "        \"answer\": answer,\n",
        "        \"messages\": [AIMessage(content=answer)]\n",
        "    }\n",
        "\n",
        "def create_chatbot_graph(embedder, dataset, index, menstrual_llama, tokenizer):\n",
        "    workflow = StateGraph(GraphState)\n",
        "    workflow.add_node(\"retrieve\", lambda state: retrieve_context(state, dataset, index, embedder))\n",
        "    workflow.add_node(\"reason_and_answer\", lambda state: generate_reasoning_and_answer(state, menstrual_llama, tokenizer))\n",
        "    workflow.add_edge(\"retrieve\", \"reason_and_answer\")\n",
        "    workflow.add_edge(\"reason_and_answer\", END)\n",
        "    workflow.set_entry_point(\"retrieve\")\n",
        "    return workflow.compile()\n",
        "\n",
        "# --- MAIN EVALUATION FUNCTION ---\n",
        "\n",
        "def run_evaluation():\n",
        "    # 1. Load Data\n",
        "    print(\"--- 1. Loading Models and Data ---\")\n",
        "    embedder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    menstrual_llama, tokenizer = load_menstrual_llama_eval()\n",
        "\n",
        "    if menstrual_llama is None:\n",
        "        return\n",
        "\n",
        "    # Load original dataset for RAG Indexing\n",
        "    try:\n",
        "        qa_pairs_rag = []\n",
        "        with open(DATASET_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "            for line in f:\n",
        "                qa_pairs_rag.append(json.loads(line))\n",
        "\n",
        "        # This dataset is only used for RAG retrieval during evaluation\n",
        "        rag_dataset = Dataset.from_list(qa_pairs_rag)\n",
        "        question_embeddings = embedder.encode(rag_dataset[\"question\"], convert_to_numpy=True)\n",
        "\n",
        "        import faiss\n",
        "        dim = question_embeddings.shape[1]\n",
        "        rag_index = faiss.IndexFlatL2(dim)\n",
        "        rag_index.add(question_embeddings)\n",
        "        print(f\"RAG Index loaded with {len(rag_dataset)} documents.\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"ERROR: RAG dataset file '{DATASET_FILE}' not found. Cannot proceed.\")\n",
        "        return\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR loading RAG index: {e}\")\n",
        "        return\n",
        "\n",
        "    # Load Golden Test Set\n",
        "    try:\n",
        "        with open(TEST_SET_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "            test_cases = [json.loads(line) for line in f]\n",
        "        print(f\"Golden Test Set loaded with {len(test_cases)} queries.\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"ERROR: Test set file '{TEST_SET_FILE}' not found. Please create it first.\")\n",
        "        return\n",
        "\n",
        "    # Initialize LangGraph\n",
        "    app = create_chatbot_graph(embedder, rag_dataset, rag_index, menstrual_llama, tokenizer)\n",
        "\n",
        "    print(\"\\n--- 2. Running Evaluation ---\")\n",
        "\n",
        "    # Metrics tracking\n",
        "    total_queries = len(test_cases)\n",
        "    total_similarity_score = 0\n",
        "    retrieval_success_count = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i, case in enumerate(test_cases):\n",
        "        print(f\"Query {i+1}/{total_queries}: {case['question'][:50]}...\")\n",
        "\n",
        "        # 2a. Run the LangGraph system\n",
        "        initial_state = {\n",
        "            \"messages\": [HumanMessage(content=case[\"question\"])],\n",
        "            \"question\": case[\"question\"],\n",
        "            \"retrieved_context\": [],\n",
        "            \"reasoning\": \"\",\n",
        "            \"answer\": \"\"\n",
        "        }\n",
        "\n",
        "        # Note: We use a static thread_id for this single-pass evaluation\n",
        "        result = app.invoke(initial_state, {\"configurable\": {\"thread_id\": \"eval_thread\"}})\n",
        "\n",
        "        # 2b. Calculate Semantic Similarity\n",
        "        generated_answer = result['answer']\n",
        "        similarity = calculate_semantic_similarity(\n",
        "            generated_answer,\n",
        "            case['ground_truth_answer'],\n",
        "            embedder\n",
        "        )\n",
        "        total_similarity_score += similarity\n",
        "\n",
        "        # 2c. Calculate Retrieval Accuracy@2 (Only for Pregnancy queries)\n",
        "        if case['is_pregnancy'] and case.get('ground_truth_question'):\n",
        "            # Check if the expected question text is present in the top 2 retrieved Q's\n",
        "            retrieved_questions = [r['question'] for r in result['retrieved_context']]\n",
        "            if case['ground_truth_question'].strip() in [q.strip() for q in retrieved_questions]:\n",
        "                retrieval_success_count += 1\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    # 3. Calculate Final Scores\n",
        "    avg_similarity = total_similarity_score / total_queries\n",
        "    # Retrieval accuracy only counts the pregnancy (RAG-reliant) queries\n",
        "    num_rag_queries = sum(1 for c in test_cases if c['is_pregnancy'])\n",
        "\n",
        "    if num_rag_queries > 0:\n",
        "        retrieval_accuracy = retrieval_success_count / num_rag_queries\n",
        "    else:\n",
        "        retrieval_accuracy = 0.0\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"         MEDLANG EVALUATION SUMMARY\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"Total Queries Tested: {total_queries}\")\n",
        "    print(f\"Total Runtime: {end_time - start_time:.2f} seconds\")\n",
        "    print(f\"Average Inference Time: {(end_time - start_time) / total_queries:.2f} seconds/query\")\n",
        "    print(\"\\n--- METRICS ---\")\n",
        "    print(f\"1. Semantic Similarity Score (Avg.): {avg_similarity:.4f}\")\n",
        "    print(f\"2. Retrieval Accuracy@2 (RAG Queries): {retrieval_accuracy:.4f} ({retrieval_success_count}/{num_rag_queries} correct)\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_evaluation()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nxx_RZbc6W_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "llama 3 8b evaluation on 120 Q/A:"
      ],
      "metadata": {
        "id": "zu7Q0KuF34ef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "import os\n",
        "import time\n",
        "from typing import Sequence\n",
        "from datasets import Dataset\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "TEST_SET_FILE = \"test_set.jsonl\"\n",
        "# Using a widely available 4-bit quantized LLaMA-3-8B-Instruct model for baseline comparison\n",
        "BASELINE_MODEL_PATH = \"unsloth/llama-3-8b-Instruct-bnb-4bit\"\n",
        "\n",
        "# --- Helper Functions ---\n",
        "\n",
        "def load_model_eval(model_path, hf_token):\n",
        "    \"\"\"Loads the LLaMA-3-8B-Instruct model with 4-bit quantization.\"\"\"\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16\n",
        "    )\n",
        "\n",
        "    print(f\"Loading Baseline Model: {model_path} with 4-bit quantization...\")\n",
        "    try:\n",
        "        # Note: AutoTokenizer from a base LLaMA-3 path often works well\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_path, token=hf_token)\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_path,\n",
        "            token=hf_token,\n",
        "            quantization_config=bnb_config,\n",
        "            device_map=\"auto\",\n",
        "        )\n",
        "        if tokenizer.pad_token is None:\n",
        "            tokenizer.pad_token = tokenizer.eos_token\n",
        "        model.eval()\n",
        "        print(\"Baseline Model loaded successfully.\")\n",
        "        return model, tokenizer\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR loading model {model_path}: {e}\")\n",
        "        return None, None\n",
        "\n",
        "def calculate_semantic_similarity(generated_answer, ground_truth, embedder):\n",
        "    \"\"\"Calculates cosine similarity between the embeddings of the two texts.\"\"\"\n",
        "    if not generated_answer or not ground_truth:\n",
        "        return 0.0\n",
        "\n",
        "    embeddings = embedder.encode(\n",
        "        [generated_answer, ground_truth],\n",
        "        convert_to_numpy=True\n",
        "    )\n",
        "    return cosine_similarity(\n",
        "        embeddings[0].reshape(1, -1),\n",
        "        embeddings[1].reshape(1, -1)\n",
        "    )[0][0]\n",
        "\n",
        "def baseline_generate(query, model, tokenizer):\n",
        "    \"\"\"\n",
        "    Generates a response using the Base LLaMA-3-Instruct model in a zero-shot manner.\n",
        "    NO RAG, simple instruction prompt focusing on detailed health answers.\n",
        "    \"\"\"\n",
        "    system_message = \"You are a helpful and expert AI assistant for women's health, providing factual, sensitive, and detailed medical information.\"\n",
        "\n",
        "    # Prompt instructs for specificity and structured output, mirroring MedLang's requirements\n",
        "    # to make the output quality comparable.\n",
        "    user_message = f\"\"\"User Question: {query}\n",
        "\n",
        "    Provide a detailed answer of 5-7 sentences. For lists of causes, symptoms, or examples, please use a numbered or bulleted list. Maintain a sensitive and factual tone.\"\"\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": user_message},\n",
        "    ]\n",
        "\n",
        "    # Model Inference (Deterministic generation for better evaluation consistency)\n",
        "    input_ids = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\").to(model.device)\n",
        "    terminators = [tokenizer.eos_token_id, tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            input_ids,\n",
        "            pad_token_id=tokenizer.pad_token_id,\n",
        "            max_new_tokens=400,\n",
        "            eos_token_id=terminators,\n",
        "            do_sample=False, # Use deterministic generation\n",
        "            temperature=0.6,\n",
        "            top_p=0.9\n",
        "        )\n",
        "\n",
        "    response_text = tokenizer.decode(outputs[0][input_ids.shape[-1]:], skip_special_tokens=True).strip()\n",
        "\n",
        "    return response_text\n",
        "\n",
        "# --- MAIN EVALUATION FUNCTION ---\n",
        "\n",
        "def run_baseline_evaluation():\n",
        "    load_dotenv()\n",
        "    hf_token = os.getenv(\"HF_TOKEN\")\n",
        "    if not hf_token:\n",
        "        print(\"ERROR: HF_TOKEN not found in .env file.\")\n",
        "        return\n",
        "\n",
        "    # 1. Load Data & Embedder\n",
        "    print(\"--- 1. Loading Models and Data ---\")\n",
        "    embedder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "    # Load Golden Test Set\n",
        "    try:\n",
        "        with open(TEST_SET_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "            test_cases = [json.loads(line) for line in f]\n",
        "        print(f\"Golden Test Set loaded with {len(test_cases)} queries.\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"ERROR: Test set file '{TEST_SET_FILE}' not found. Please create it first.\")\n",
        "        return\n",
        "\n",
        "    # Load Baseline Model\n",
        "    baseline_model, baseline_tokenizer = load_model_eval(BASELINE_MODEL_PATH, hf_token)\n",
        "\n",
        "    if not baseline_model:\n",
        "        return\n",
        "\n",
        "    print(\"\\n--- 2. Running Baseline Evaluation (LLaMA-3 Zero-Shot) ---\")\n",
        "\n",
        "    # Metrics tracking\n",
        "    total_queries = len(test_cases)\n",
        "    baseline_similarity_score = 0\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i, case in enumerate(test_cases):\n",
        "        print(f\"Query {i+1}/{total_queries}: {case['question'][:50]}...\")\n",
        "\n",
        "        query = case[\"question\"]\n",
        "        gt_answer = case['ground_truth_answer']\n",
        "\n",
        "        # 2a. LLaMA-3 Baseline Generation (Zero-Shot)\n",
        "        generated_answer = baseline_generate(query, baseline_model, baseline_tokenizer)\n",
        "\n",
        "        # 2b. Calculate Semantic Similarity\n",
        "        similarity = calculate_semantic_similarity(generated_answer, gt_answer, embedder)\n",
        "        baseline_similarity_score += similarity\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    # 3. Calculate Final Scores\n",
        "    avg_baseline_similarity = baseline_similarity_score / total_queries\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"      LLaMA-3 BASELINE EVALUATION SUMMARY\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"Total Queries Tested: {total_queries}\")\n",
        "    print(f\"Total Runtime: {end_time - start_time:.2f} seconds\")\n",
        "    print(f\"Average Inference Time: {(end_time - start_time) / total_queries:.2f} seconds/query\")\n",
        "    print(\"\\n--- METRICS ---\")\n",
        "    print(f\"1. LLaMA-3 Baseline (Zero-Shot) Avg. Semantic Similarity: {avg_baseline_similarity:.4f}\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_baseline_evaluation()"
      ],
      "metadata": {
        "id": "ol9tscpD3-iw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "fcee845e18cc4e00bc773297dcc9191a",
            "240e0e8b39034c9a9d2f798fff6aa08c",
            "f9c52ba9793141b685d41ee3723ead44",
            "34aaf1f1f7a64cd7ac906d8ec95e3b98",
            "f908268770284ae3bcc97a42217477e8",
            "5b9d0156d22e43eb88c4303b33b74502",
            "c07712a050494b8bb5282251874420e5",
            "d9e695255854497fac54005ea813022e",
            "cf2bee3aca6d4f8fb0de51012ae21dba",
            "d0d5043c543648908369ea092bdbece0",
            "20a559c62291449fbf0e49ab93449516",
            "ddb6c439e96e411792139a7ce1eaabd2",
            "248d6b4dfa4f45e5801afa7c2f7c7415",
            "170b2d73726e4a0b8850ddd686079cc2",
            "c65492fd497343e0a9c44c1f62827a76",
            "ea00bf8ada8149f1a1ccfa0078f67eff",
            "8052f492a1654ef0b21af299ef084b73",
            "755f411968da4ed582912bf49143afb0",
            "565e70d8a5df46c59211093520ba041f",
            "8306968af1a24f55936cf190db6f3f6f",
            "065d278cb8044919830959b296fb28c3",
            "0caf29c217674f168f1c63a47f2b338d",
            "8a202f05aadd415d9c3714c297db3277",
            "d11947cd6502417183ad8d1c620e2f60",
            "70173c8ed1944232a0d7bdc8f848c21c",
            "1898107a68e5481fbf252316c79c5eb8",
            "b56b6ed66c304f45a3abe724df00b83f",
            "f67b72a6a52f4d2ea172c01822318982",
            "150b31b036054a28a542be1ec974f2d7",
            "ddce370f703e41a5b1dda011e8f3d090",
            "de50efd63ac8471787c381c4071a3257",
            "77956b0c2785418aba4b65effe43b4af",
            "038bd16efe2c4663a536bd7f04cb3986",
            "569cc83a380b42d3add71b79fea66568",
            "895451e1f0934d2e89b001bd0bd7961d",
            "72d5fc0873394a3392c2e1a52cc2738f",
            "dcb7bd9f521b462a97e10bdd866e020a",
            "9e5f9d1264d24d49a5b8e02292e09d02",
            "ad938e2a8b64491199e1c34d869f16d6",
            "b2e4f44f7e304ced80a286e8421e2101",
            "342b5ad4234e4f4db5e69ad0622d5698",
            "1444983a312c42e5871f0dfebbda9c30",
            "94af30bc55c54fcd852c9c7f09f78db4",
            "91c9eb8ea024479a93ef2ed417e571a0",
            "a9add5556dbd48b7bfa875576129230c",
            "51710682afca4de69d63b15e61ee78aa",
            "bd7aa231691742e294a7b8838a1449db",
            "5d7648196aea42ce9d3ca971d0deb850",
            "b48df82a1a8a44b7a49551d1358fdad8",
            "0cff025b8fcb465f901e4a5b7da1b2ec",
            "eacd5c540f01488f9a0755275e59bc7c",
            "cea753fc26564b1b927b4d46e055530e",
            "da090d3f73494864914654d49563ee37",
            "4eff8e4da2e048ac80dbf379a483bae5",
            "9ae9946934254165845bf299d378ebe7",
            "3bc68ce05c9442038fec3fedd83a3bad",
            "c99056c000de463db456d69d24befe77",
            "eaddf0c4fbd34e2096626b5fe3c0db6e",
            "9e05befd7bfa49a9bd86462495583114",
            "05e64d7236f7426badb8c953a04c7414",
            "7046f206e8ea48bdb8b3ccd634ceee9d",
            "2232f269954d4c938142b4552c7323b1",
            "30cf78564c1a40e5b40001cc06bb8c3c",
            "95d6a6bb62e043bf9cd2286f220ebf16",
            "abbf2a4cf80a4df8a2832d8e74ff65df",
            "4df2c104b5aa43b1b16c2b90e9e63793"
          ]
        },
        "outputId": "3eaf3f68-77f8-49ed-9cee-897b6afe0d53"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 1. Loading Models and Data ---\n",
            "Golden Test Set loaded with 120 queries.\n",
            "Loading Baseline Model: unsloth/llama-3-8b-Instruct-bnb-4bit with 4-bit quantization...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fcee845e18cc4e00bc773297dcc9191a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ddb6c439e96e411792139a7ce1eaabd2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/345 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a202f05aadd415d9c3714c297db3277"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "569cc83a380b42d3add71b79fea66568"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/quantizers/auto.py:239: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
            "  warnings.warn(warning_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a9add5556dbd48b7bfa875576129230c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/220 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3bc68ce05c9442038fec3fedd83a3bad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Model loaded successfully.\n",
            "\n",
            "--- 2. Running Baseline Evaluation (LLaMA-3 Zero-Shot) ---\n",
            "Query 1/120: What is the scientific term for \"chumps\" or \"perio...\n",
            "Query 2/120: What is â€œmenarcheâ€?...\n",
            "Query 3/120: At what age do menses usually begin?...\n",
            "Query 4/120: What happens during menses?...\n",
            "Query 5/120: For how long does the bleeding last?...\n",
            "Query 6/120: Is it very painful?...\n",
            "Query 7/120: What is a sanitary pad?...\n",
            "Query 8/120: Is it okay to use a cloth instead of a sanitary pa...\n",
            "Query 9/120: Are sanitary pads too costly?...\n",
            "Query 10/120: Can sanitary pads be availed free of cost?...\n",
            "Query 11/120: What needs to be done after using a sanitary pad?...\n",
            "Query 12/120: What is the proper way to dispose of sanitary pads...\n",
            "Query 13/120: Can sanitary pads be disposed of in a commode?...\n",
            "Query 14/120: How many sanitary pads are required per month?...\n",
            "Query 15/120: How often should sanitary pads be changed during t...\n",
            "Query 16/120: What will happen if I use the same sanitary pad fo...\n",
            "Query 17/120: Is there an alternative to sanitary pads?...\n",
            "Query 18/120: Can a virgin use a menstrual cup?...\n",
            "Query 19/120: Are menstrual cups reusable?...\n",
            "Query 20/120: What is a tampon?...\n",
            "Query 21/120: Are tampons reusable?...\n",
            "Query 22/120: What is the proper way to dispose of tampons?...\n",
            "Query 23/120: How do I take the tampon out of my vagina?...\n",
            "Query 24/120: What will happen if the tampon does not come out?...\n",
            "Query 25/120: Do I need training before using a tampon?...\n",
            "Query 26/120: What should I do if a tampon is stuck inside and i...\n",
            "Query 27/120: Why do infections occur if sanitary pads or tampon...\n",
            "Query 28/120: What type of food should I eat during menses?...\n",
            "Query 29/120: What are some rules of hygiene during menses?...\n",
            "Query 30/120: Why do elders insist on not having a head bath dur...\n",
            "Query 31/120: What is premenstrual syndrome that people usually ...\n",
            "Query 32/120: Why does one get premenstrual syndrome?...\n",
            "Query 33/120: What kind of exercise should I do during menses?...\n",
            "Query 34/120: Can I prepone or postpone my period?...\n",
            "Query 35/120: What kind of clothes should be worn during menses?...\n",
            "Query 36/120: How can I keep track of my menstrual cycle?...\n",
            "Query 37/120: Is it normal for my period to smell?...\n",
            "Query 38/120: What are the common reasons for missed or late per...\n",
            "Query 39/120: How much blood do I lose during my period?...\n",
            "Query 40/120: When will I stop having my period for good?...\n",
            "Query 41/120: Am I pregnant if I miss my periods?...\n",
            "Query 42/120: Why did I bleed for more days in this cycle?...\n",
            "Query 43/120: Are my painful cramps normal? When should I tell m...\n",
            "Query 44/120: Is it normal to have periods twice a month?...\n",
            "Query 45/120: Where is the uterus located?...\n",
            "Query 46/120: Which organs are responsible for menstruation?...\n",
            "Query 47/120: How many ovaries are present in a woman?...\n",
            "Query 48/120: What is the normal interval between two menstrual ...\n",
            "Query 49/120: How many eggs are normally released in a month?...\n",
            "Query 50/120: What is a sign of ovulation?...\n",
            "Query 51/120: What foods should I avoid or limit while breastfee...\n",
            "Query 52/120: How can I manage extreme tiredness or exhaustion d...\n",
            "Query 53/120: What steps should I take to treat a clogged milk d...\n",
            "Query 54/120: How many necessary vaccines are recommended for my...\n",
            "Query 55/120: At what temperature should I be concerned about my...\n",
            "Query 56/120: Why is my baby consistently congested every single...\n",
            "Query 57/120: Around what age do most babies begin talking or sp...\n",
            "Query 58/120: How frequently is it appropriate or necessary to s...\n",
            "Query 59/120: What is the typical visual acuity for a 4-month-ol...\n",
            "Query 60/120: Is my baby able to detect light when I am 18 weeks...\n",
            "Query 61/120: What range is considered a normal blood pressure r...\n",
            "Query 62/120: What sensory experiences are infants typically hav...\n",
            "Query 63/120: When is the recommended time or age for me to stop...\n",
            "Query 64/120: What is the best time to switch my baby from formu...\n",
            "Query 65/120: How frequently should I be feeding my baby?...\n",
            "Query 66/120: What are some engaging and age-appropriate games I...\n",
            "Query 67/120: Is it better for my baby to use a pacifier or suck...\n",
            "Query 68/120: What is the most effective method to encourage my ...\n",
            "Query 69/120: My two-year-old is not communicating. What might b...\n",
            "Query 70/120: How can I determine if my baby is having an allerg...\n",
            "Query 71/120: What is the normal and reassuring frequency for fe...\n",
            "Query 72/120: Is experiencing heartburn a common symptom at 21 w...\n",
            "Query 73/120: Can I hear or feel my baby's joints crack or pop?...\n",
            "Query 74/120: What amount of crying is considered normal for a n...\n",
            "Query 75/120: What is the underlying cause for my constant feeli...\n",
            "Query 76/120: I am experiencing fatigue and weakness; what are t...\n",
            "Query 77/120: Why am I constantly feeling exhausted and physical...\n",
            "Query 78/120: Could you list the reasons for feeling fatigued an...\n",
            "Query 79/120: Why do I experience pain or a burning sensation wh...\n",
            "Query 80/120: What causes the pain or burning sensation during u...\n",
            "Query 81/120: What's the reason for the painful or burning feeli...\n",
            "Query 82/120: What could be causing the burning sensation when I...\n",
            "Query 83/120: I have fever, tiredness, and shakiness. What shoul...\n",
            "Query 84/120: What are the possible causes for my fever, fatigue...\n",
            "Query 85/120: Why am I feeling feverish, fatigued, and shaky?...\n",
            "Query 86/120: Could you tell me the reasons for feeling feverish...\n",
            "Query 87/120: What is the cause of my sad or depressed mood?...\n",
            "Query 88/120: What are the possible causes for my persistent low...\n",
            "Query 89/120: Why do I feel depressed or generally down?...\n",
            "Query 90/120: What are the reasons for feeling sad or consistent...\n",
            "Query 91/120: What are the causes of my high blood pressure duri...\n",
            "Query 92/120: Could you list the factors causing my elevated blo...\n",
            "Query 93/120: What are the potential reasons for hypertension du...\n",
            "Query 94/120: What leads to elevated blood pressure during the p...\n",
            "Query 95/120: What is the reason my blood glucose levels are hig...\n",
            "Query 96/120: What are the risk factors for having high blood su...\n",
            "Query 97/120: What leads to elevated glucose levels during pregn...\n",
            "Query 98/120: Can you explain the causes of high blood sugar in ...\n",
            "Query 99/120: Could you define what preeclampsia is and list its...\n",
            "Query 100/120: I need an explanation of preeclampsia during pregn...\n",
            "Query 101/120: Can you give me the details regarding the conditio...\n",
            "Query 102/120: How should I understand the term preeclampsia in t...\n",
            "Query 103/120: Why am I experiencing labor pains before my expect...\n",
            "Query 104/120: What causes the contractions I am feeling before m...\n",
            "Query 105/120: Why are my labor pains starting so early?...\n",
            "Query 106/120: Could you explain the reasons for having contracti...\n",
            "Query 107/120: Why am I vomiting so frequently during my pregnanc...\n",
            "Query 108/120: What could be the cause of my excessive vomiting t...\n",
            "Query 109/120: What is the reason I am experiencing frequent, sev...\n",
            "Query 110/120: What causes severe vomiting during pregnancy, like...\n",
            "Query 111/120: What is the cause of my swollen feet during pregna...\n",
            "Query 112/120: I have swelling in my feet. What might be causing ...\n",
            "Query 113/120: Why have my feet become swollen during my pregnanc...\n",
            "Query 114/120: Are swollen feet a normal symptom of pregnancy? Wh...\n",
            "Query 115/120: Can you list the risks associated with obesity dur...\n",
            "Query 116/120: How does pre-pregnancy obesity impact potential co...\n",
            "Query 117/120: What are the consequences of being obese before an...\n",
            "Query 118/120: Is it possible for a malaria infection to cause a ...\n",
            "Query 119/120: What dangers does malaria pose to pregnant women a...\n",
            "Query 120/120: How specifically does malaria impact the course of...\n",
            "\n",
            "==================================================\n",
            "      LLaMA-3 BASELINE EVALUATION SUMMARY\n",
            "==================================================\n",
            "Total Queries Tested: 120\n",
            "Total Runtime: 2783.42 seconds\n",
            "Average Inference Time: 23.20 seconds/query\n",
            "\n",
            "--- METRICS ---\n",
            "1. LLaMA-3 Baseline (Zero-Shot) Avg. Semantic Similarity: 0.7075\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3iSf-8L34YRF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "05e30cbdf47a42518df13f6bf58e85b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59383bcce8e04515b9fa074e7fee7df8",
              "IPY_MODEL_7e7f696ce5544e30911f07c46dbbc061",
              "IPY_MODEL_0fb328555ac848efbb4ff9f30057142b"
            ],
            "layout": "IPY_MODEL_66f90f324d414810a9e86421aa507dcf"
          }
        },
        "59383bcce8e04515b9fa074e7fee7df8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98b06d9b301040f78bd37d6fedc2efeb",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_46ff99c632f848fd9795201cfe2d4591",
            "value": "Loadingâ€‡checkpointâ€‡shards:â€‡100%"
          }
        },
        "7e7f696ce5544e30911f07c46dbbc061": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14e648809751439fa9b5ae61b87ce684",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ed4dd71da86494ea10f4443a5f1b1da",
            "value": 4
          }
        },
        "0fb328555ac848efbb4ff9f30057142b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_774c8c26392441daa8b0090f7861a816",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d8914704a2674776b783a8c0eb86cdfb",
            "value": "â€‡4/4â€‡[01:43&lt;00:00,â€‡20.85s/it]"
          }
        },
        "66f90f324d414810a9e86421aa507dcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98b06d9b301040f78bd37d6fedc2efeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46ff99c632f848fd9795201cfe2d4591": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14e648809751439fa9b5ae61b87ce684": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ed4dd71da86494ea10f4443a5f1b1da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "774c8c26392441daa8b0090f7861a816": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8914704a2674776b783a8c0eb86cdfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fcee845e18cc4e00bc773297dcc9191a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_240e0e8b39034c9a9d2f798fff6aa08c",
              "IPY_MODEL_f9c52ba9793141b685d41ee3723ead44",
              "IPY_MODEL_34aaf1f1f7a64cd7ac906d8ec95e3b98"
            ],
            "layout": "IPY_MODEL_f908268770284ae3bcc97a42217477e8"
          }
        },
        "240e0e8b39034c9a9d2f798fff6aa08c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b9d0156d22e43eb88c4303b33b74502",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c07712a050494b8bb5282251874420e5",
            "value": "tokenizer_config.json:â€‡"
          }
        },
        "f9c52ba9793141b685d41ee3723ead44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9e695255854497fac54005ea813022e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cf2bee3aca6d4f8fb0de51012ae21dba",
            "value": 1
          }
        },
        "34aaf1f1f7a64cd7ac906d8ec95e3b98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0d5043c543648908369ea092bdbece0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_20a559c62291449fbf0e49ab93449516",
            "value": "â€‡51.1k/?â€‡[00:00&lt;00:00,â€‡1.47MB/s]"
          }
        },
        "f908268770284ae3bcc97a42217477e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b9d0156d22e43eb88c4303b33b74502": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c07712a050494b8bb5282251874420e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9e695255854497fac54005ea813022e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "cf2bee3aca6d4f8fb0de51012ae21dba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d0d5043c543648908369ea092bdbece0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20a559c62291449fbf0e49ab93449516": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ddb6c439e96e411792139a7ce1eaabd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_248d6b4dfa4f45e5801afa7c2f7c7415",
              "IPY_MODEL_170b2d73726e4a0b8850ddd686079cc2",
              "IPY_MODEL_c65492fd497343e0a9c44c1f62827a76"
            ],
            "layout": "IPY_MODEL_ea00bf8ada8149f1a1ccfa0078f67eff"
          }
        },
        "248d6b4dfa4f45e5801afa7c2f7c7415": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8052f492a1654ef0b21af299ef084b73",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_755f411968da4ed582912bf49143afb0",
            "value": "tokenizer.json:â€‡"
          }
        },
        "170b2d73726e4a0b8850ddd686079cc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_565e70d8a5df46c59211093520ba041f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8306968af1a24f55936cf190db6f3f6f",
            "value": 1
          }
        },
        "c65492fd497343e0a9c44c1f62827a76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_065d278cb8044919830959b296fb28c3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0caf29c217674f168f1c63a47f2b338d",
            "value": "â€‡9.09M/?â€‡[00:00&lt;00:00,â€‡22.6MB/s]"
          }
        },
        "ea00bf8ada8149f1a1ccfa0078f67eff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8052f492a1654ef0b21af299ef084b73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "755f411968da4ed582912bf49143afb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "565e70d8a5df46c59211093520ba041f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "8306968af1a24f55936cf190db6f3f6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "065d278cb8044919830959b296fb28c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0caf29c217674f168f1c63a47f2b338d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a202f05aadd415d9c3714c297db3277": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d11947cd6502417183ad8d1c620e2f60",
              "IPY_MODEL_70173c8ed1944232a0d7bdc8f848c21c",
              "IPY_MODEL_1898107a68e5481fbf252316c79c5eb8"
            ],
            "layout": "IPY_MODEL_b56b6ed66c304f45a3abe724df00b83f"
          }
        },
        "d11947cd6502417183ad8d1c620e2f60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f67b72a6a52f4d2ea172c01822318982",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_150b31b036054a28a542be1ec974f2d7",
            "value": "special_tokens_map.json:â€‡100%"
          }
        },
        "70173c8ed1944232a0d7bdc8f848c21c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddce370f703e41a5b1dda011e8f3d090",
            "max": 345,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_de50efd63ac8471787c381c4071a3257",
            "value": 345
          }
        },
        "1898107a68e5481fbf252316c79c5eb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77956b0c2785418aba4b65effe43b4af",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_038bd16efe2c4663a536bd7f04cb3986",
            "value": "â€‡345/345â€‡[00:00&lt;00:00,â€‡9.48kB/s]"
          }
        },
        "b56b6ed66c304f45a3abe724df00b83f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f67b72a6a52f4d2ea172c01822318982": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "150b31b036054a28a542be1ec974f2d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ddce370f703e41a5b1dda011e8f3d090": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de50efd63ac8471787c381c4071a3257": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77956b0c2785418aba4b65effe43b4af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "038bd16efe2c4663a536bd7f04cb3986": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "569cc83a380b42d3add71b79fea66568": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_895451e1f0934d2e89b001bd0bd7961d",
              "IPY_MODEL_72d5fc0873394a3392c2e1a52cc2738f",
              "IPY_MODEL_dcb7bd9f521b462a97e10bdd866e020a"
            ],
            "layout": "IPY_MODEL_9e5f9d1264d24d49a5b8e02292e09d02"
          }
        },
        "895451e1f0934d2e89b001bd0bd7961d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad938e2a8b64491199e1c34d869f16d6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b2e4f44f7e304ced80a286e8421e2101",
            "value": "config.json:â€‡"
          }
        },
        "72d5fc0873394a3392c2e1a52cc2738f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_342b5ad4234e4f4db5e69ad0622d5698",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1444983a312c42e5871f0dfebbda9c30",
            "value": 1
          }
        },
        "dcb7bd9f521b462a97e10bdd866e020a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94af30bc55c54fcd852c9c7f09f78db4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_91c9eb8ea024479a93ef2ed417e571a0",
            "value": "â€‡1.26k/?â€‡[00:00&lt;00:00,â€‡53.4kB/s]"
          }
        },
        "9e5f9d1264d24d49a5b8e02292e09d02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad938e2a8b64491199e1c34d869f16d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2e4f44f7e304ced80a286e8421e2101": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "342b5ad4234e4f4db5e69ad0622d5698": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "1444983a312c42e5871f0dfebbda9c30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "94af30bc55c54fcd852c9c7f09f78db4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91c9eb8ea024479a93ef2ed417e571a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9add5556dbd48b7bfa875576129230c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51710682afca4de69d63b15e61ee78aa",
              "IPY_MODEL_bd7aa231691742e294a7b8838a1449db",
              "IPY_MODEL_5d7648196aea42ce9d3ca971d0deb850"
            ],
            "layout": "IPY_MODEL_b48df82a1a8a44b7a49551d1358fdad8"
          }
        },
        "51710682afca4de69d63b15e61ee78aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cff025b8fcb465f901e4a5b7da1b2ec",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_eacd5c540f01488f9a0755275e59bc7c",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "bd7aa231691742e294a7b8838a1449db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cea753fc26564b1b927b4d46e055530e",
            "max": 5702746403,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da090d3f73494864914654d49563ee37",
            "value": 5702746403
          }
        },
        "5d7648196aea42ce9d3ca971d0deb850": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4eff8e4da2e048ac80dbf379a483bae5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9ae9946934254165845bf299d378ebe7",
            "value": "â€‡5.70G/5.70Gâ€‡[00:58&lt;00:00,â€‡118MB/s]"
          }
        },
        "b48df82a1a8a44b7a49551d1358fdad8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cff025b8fcb465f901e4a5b7da1b2ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eacd5c540f01488f9a0755275e59bc7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cea753fc26564b1b927b4d46e055530e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da090d3f73494864914654d49563ee37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4eff8e4da2e048ac80dbf379a483bae5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ae9946934254165845bf299d378ebe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3bc68ce05c9442038fec3fedd83a3bad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c99056c000de463db456d69d24befe77",
              "IPY_MODEL_eaddf0c4fbd34e2096626b5fe3c0db6e",
              "IPY_MODEL_9e05befd7bfa49a9bd86462495583114"
            ],
            "layout": "IPY_MODEL_05e64d7236f7426badb8c953a04c7414"
          }
        },
        "c99056c000de463db456d69d24befe77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7046f206e8ea48bdb8b3ccd634ceee9d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2232f269954d4c938142b4552c7323b1",
            "value": "generation_config.json:â€‡100%"
          }
        },
        "eaddf0c4fbd34e2096626b5fe3c0db6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30cf78564c1a40e5b40001cc06bb8c3c",
            "max": 220,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_95d6a6bb62e043bf9cd2286f220ebf16",
            "value": 220
          }
        },
        "9e05befd7bfa49a9bd86462495583114": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abbf2a4cf80a4df8a2832d8e74ff65df",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4df2c104b5aa43b1b16c2b90e9e63793",
            "value": "â€‡220/220â€‡[00:00&lt;00:00,â€‡24.0kB/s]"
          }
        },
        "05e64d7236f7426badb8c953a04c7414": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7046f206e8ea48bdb8b3ccd634ceee9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2232f269954d4c938142b4552c7323b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30cf78564c1a40e5b40001cc06bb8c3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95d6a6bb62e043bf9cd2286f220ebf16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "abbf2a4cf80a4df8a2832d8e74ff65df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4df2c104b5aa43b1b16c2b90e9e63793": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}